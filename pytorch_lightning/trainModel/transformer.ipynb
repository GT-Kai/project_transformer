{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8857c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy                  \n",
    "import math                  \n",
    "\n",
    "import torch                  \n",
    "from torch import nn                  \n",
    "from torch.functional import F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3158e8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                           Version\n",
      "--------------------------------- -----------\n",
      "accessible-pygments               0.0.5\n",
      "alabaster                         1.0.0\n",
      "alphabase                         1.7.2\n",
      "alpharaw                          0.4.8\n",
      "alphatims                         1.0.9\n",
      "annotated-types                   0.7.0\n",
      "anyio                             4.11.0\n",
      "argon2-cffi                       25.1.0\n",
      "argon2-cffi-bindings              25.1.0\n",
      "arrow                             1.4.0\n",
      "asttokens                         3.0.0\n",
      "async-lru                         2.0.5\n",
      "attrs                             25.4.0\n",
      "autodocsumm                       0.2.14\n",
      "babel                             2.17.0\n",
      "beautifulsoup4                    4.14.2\n",
      "biopython                         1.85\n",
      "bleach                            6.2.0\n",
      "boto3                             1.40.59\n",
      "botocore                          1.40.59\n",
      "bracex                            2.6\n",
      "bravado                           11.1.0\n",
      "bravado-core                      6.1.1\n",
      "bump-my-version                   1.2.4\n",
      "certifi                           2025.10.5\n",
      "cffi                              2.0.0\n",
      "cfgv                              3.4.0\n",
      "charset-normalizer                3.4.4\n",
      "click                             8.2.1\n",
      "clr_loader                        0.2.8\n",
      "comm                              0.2.3\n",
      "contextfilter                     0.3.0\n",
      "contextlib2                       21.6.0\n",
      "contourpy                         1.3.3\n",
      "coverage                          7.11.0\n",
      "coverage-badge                    1.1.2\n",
      "cycler                            0.12.1\n",
      "debugpy                           1.8.17\n",
      "decorator                         5.2.1\n",
      "defusedxml                        0.7.1\n",
      "distlib                           0.4.0\n",
      "docutils                          0.21.2\n",
      "executing                         2.2.1\n",
      "fair-esm                          2.0.0\n",
      "faiss-cpu                         1.12.0\n",
      "fastjsonschema                    2.21.2\n",
      "fennomix-mhc                      0.0.1.dev0\n",
      "filelock                          3.20.0\n",
      "fonttools                         4.60.1\n",
      "fqdn                              1.5.1\n",
      "fsspec                            2025.9.0\n",
      "furo                              2025.9.25\n",
      "future                            1.0.0\n",
      "gitdb                             4.0.12\n",
      "GitPython                         3.1.45\n",
      "h11                               0.16.0\n",
      "h5py                              3.15.1\n",
      "hf-xet                            1.2.0\n",
      "httpcore                          1.0.9\n",
      "httpx                             0.28.1\n",
      "huggingface-hub                   0.36.0\n",
      "identify                          2.6.15\n",
      "idna                              3.11\n",
      "imagesize                         1.4.1\n",
      "importlib_resources               6.5.2\n",
      "iniconfig                         2.3.0\n",
      "ipykernel                         7.0.1\n",
      "ipython                           9.6.0\n",
      "ipython-genutils                  0.2.0\n",
      "ipython_pygments_lexers           1.1.1\n",
      "ipywidgets                        8.1.7\n",
      "isoduration                       20.11.0\n",
      "jedi                              0.19.2\n",
      "Jinja2                            3.1.6\n",
      "jmespath                          1.0.1\n",
      "joblib                            1.5.2\n",
      "json5                             0.12.1\n",
      "jsonpointer                       3.0.0\n",
      "jsonref                           1.1.0\n",
      "jsonschema                        4.25.1\n",
      "jsonschema-specifications         2025.9.1\n",
      "jupyter                           1.1.1\n",
      "jupyter_client                    8.6.3\n",
      "jupyter-console                   6.6.3\n",
      "jupyter_contrib_core              0.4.2\n",
      "jupyter_contrib_nbextensions      0.7.0\n",
      "jupyter_core                      5.9.1\n",
      "jupyter-events                    0.12.0\n",
      "jupyter-highlight-selected-word   0.2.0\n",
      "jupyter-lsp                       2.3.0\n",
      "jupyter_nbextensions_configurator 0.6.4\n",
      "jupyter_server                    2.17.0\n",
      "jupyter_server_terminals          0.5.3\n",
      "jupyterlab                        4.4.10\n",
      "jupyterlab_pygments               0.3.0\n",
      "jupyterlab_server                 2.28.0\n",
      "jupyterlab_widgets                3.0.15\n",
      "kiwisolver                        1.4.9\n",
      "lark                              1.3.0\n",
      "llvmlite                          0.45.1\n",
      "logomaker                         0.8.7\n",
      "lxml                              6.0.2\n",
      "markdown-it-py                    3.0.0\n",
      "MarkupSafe                        3.0.3\n",
      "matplotlib                        3.10.7\n",
      "matplotlib-inline                 0.2.1\n",
      "mdit-py-plugins                   0.5.0\n",
      "mdurl                             0.1.2\n",
      "mistune                           3.1.4\n",
      "monotonic                         1.6\n",
      "mpmath                            1.3.0\n",
      "msgpack                           1.1.2\n",
      "myst-parser                       4.0.1\n",
      "narwhals                          2.9.0\n",
      "nbclient                          0.10.2\n",
      "nbconvert                         7.16.6\n",
      "nbformat                          5.10.4\n",
      "nbsphinx                          0.9.7\n",
      "neptune                           1.14.0\n",
      "nest-asyncio                      1.6.0\n",
      "networkx                          3.5\n",
      "nodeenv                           1.9.1\n",
      "notebook                          7.4.7\n",
      "notebook_shim                     0.2.4\n",
      "numba                             0.62.1\n",
      "numpy                             1.26.4\n",
      "nvidia-cublas-cu12                12.4.5.8\n",
      "nvidia-cuda-cupti-cu12            12.4.127\n",
      "nvidia-cuda-nvrtc-cu12            12.4.127\n",
      "nvidia-cuda-runtime-cu12          12.4.127\n",
      "nvidia-cudnn-cu12                 9.1.0.70\n",
      "nvidia-cufft-cu12                 11.2.1.3\n",
      "nvidia-curand-cu12                10.3.5.147\n",
      "nvidia-cusolver-cu12              11.6.1.9\n",
      "nvidia-cusparse-cu12              12.3.1.170\n",
      "nvidia-cusparselt-cu12            0.6.2\n",
      "nvidia-nccl-cu12                  2.21.5\n",
      "nvidia-nvjitlink-cu12             12.4.127\n",
      "nvidia-nvtx-cu12                  12.4.127\n",
      "oauthlib                          3.3.1\n",
      "overrides                         7.7.0\n",
      "packaging                         25.0\n",
      "pandas                            2.3.3\n",
      "pandoc                            2.4\n",
      "pandocfilters                     1.5.1\n",
      "parso                             0.8.5\n",
      "peptdeep                          1.4.0\n",
      "pexpect                           4.9.0\n",
      "pillow                            12.0.0\n",
      "pip                               25.3\n",
      "pipdeptree                        2.29.0\n",
      "platformdirs                      4.5.0\n",
      "plotly                            6.3.1\n",
      "pluggy                            1.6.0\n",
      "plumbum                           1.9.0\n",
      "ply                               3.11\n",
      "pre-commit                        3.7.0\n",
      "prometheus_client                 0.23.1\n",
      "prompt_toolkit                    3.0.52\n",
      "psutil                            7.1.2\n",
      "ptyprocess                        0.7.0\n",
      "pure_eval                         0.2.3\n",
      "pyahocorasick                     2.2.0\n",
      "pyarrow                           20.0.0\n",
      "pycparser                         2.23\n",
      "pydantic                          2.12.3\n",
      "pydantic_core                     2.41.4\n",
      "pydantic-settings                 2.11.0\n",
      "pydivsufsort                      0.0.18\n",
      "Pygments                          2.19.2\n",
      "PyJWT                             2.10.1\n",
      "pynndescent                       0.5.13\n",
      "pyparsing                         3.2.5\n",
      "pyteomics                         4.7.5\n",
      "pytest                            8.4.2\n",
      "python-dateutil                   2.9.0.post0\n",
      "python-dotenv                     1.2.1\n",
      "python-json-logger                4.0.0\n",
      "pythonnet                         3.0.5\n",
      "pytz                              2025.2\n",
      "PyYAML                            6.0.3\n",
      "pyzmq                             27.1.0\n",
      "pyzstd                            0.18.0\n",
      "questionary                       2.1.1\n",
      "rdkit                             2024.3.2\n",
      "referencing                       0.37.0\n",
      "regex                             2025.10.23\n",
      "requests                          2.32.5\n",
      "requests-oauthlib                 2.0.0\n",
      "rfc3339-validator                 0.1.4\n",
      "rfc3986-validator                 0.1.1\n",
      "rfc3987-syntax                    1.1.0\n",
      "rich                              14.2.0\n",
      "rich-click                        1.9.4\n",
      "rpds-py                           0.28.0\n",
      "s3transfer                        0.14.0\n",
      "safetensors                       0.6.2\n",
      "scikit-learn                      1.7.2\n",
      "scikit-misc                       0.5.1\n",
      "scipy                             1.16.2\n",
      "Send2Trash                        1.8.3\n",
      "setuptools                        80.9.0\n",
      "simplejson                        3.20.2\n",
      "six                               1.17.0\n",
      "smmap                             5.0.2\n",
      "sniffio                           1.3.1\n",
      "snowballstemmer                   3.0.1\n",
      "soupsieve                         2.8\n",
      "Sphinx                            8.1.3\n",
      "sphinx-autodoc-typehints          3.0.1\n",
      "sphinx-basic-ng                   1.0.0b2\n",
      "sphinx_design                     0.6.1\n",
      "sphinx-rtd-theme                  3.0.2\n",
      "sphinxcontrib-applehelp           2.0.0\n",
      "sphinxcontrib-devhelp             2.0.0\n",
      "sphinxcontrib-htmlhelp            2.1.0\n",
      "sphinxcontrib-jquery              4.1\n",
      "sphinxcontrib-jsmath              1.0.1\n",
      "sphinxcontrib-qthelp              2.0.0\n",
      "sphinxcontrib-serializinghtml     2.0.0\n",
      "stack-data                        0.6.3\n",
      "swagger-spec-validator            3.0.4\n",
      "sympy                             1.13.1\n",
      "terminado                         0.18.1\n",
      "threadpoolctl                     3.6.0\n",
      "tinycss2                          1.4.0\n",
      "tokenizers                        0.22.1\n",
      "tomlkit                           0.13.3\n",
      "torch                             2.6.0\n",
      "tornado                           6.5.2\n",
      "tqdm                              4.67.1\n",
      "traitlets                         5.14.3\n",
      "transformers                      4.57.1\n",
      "triton                            3.2.0\n",
      "typing_extensions                 4.15.0\n",
      "typing-inspection                 0.4.2\n",
      "tzdata                            2025.2\n",
      "umap-learn                        0.5.9.post2\n",
      "uri-template                      1.3.0\n",
      "urllib3                           2.5.0\n",
      "virtualenv                        20.35.3\n",
      "wcmatch                           10.1\n",
      "wcwidth                           0.2.14\n",
      "webcolors                         24.11.1\n",
      "webencodings                      0.5.1\n",
      "websocket-client                  1.9.0\n",
      "wheel                             0.45.1\n",
      "widgetsnbextension                4.0.14\n",
      "xxhash                            3.6.0\n"
     ]
    }
   ],
   "source": [
    "! pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f146b0bd",
   "metadata": {},
   "source": [
    "## 词嵌入Embedding\n",
    "词嵌入是将离散的文本符号（如单词、子词）映射为连续低维向量的过程。在PyTorch中通常通过nn.Embedding实现，它将每个词的索引转换为固定维度的稠密向量，使模型能够捕捉词语间的语义关联，为后续的注意力计算和特征提取奠定数值基础。\n",
    "\n",
    "广义的embedding是指将自然语言字符串转换为向量的过程，各个大模型LLM均有自己的分词器和词汇表，在进入Transformer的embedding前已经将自然语言处理成了二维矩阵张量。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638d6166",
   "metadata": {},
   "source": [
    "![Embedding](figures/a65c3e7a01e4ac3606f7c2b7a70ecfee.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0c85a9",
   "metadata": {},
   "source": [
    "图示张量为[[39,1592,10,2548,5]]\n",
    "\n",
    "第一维（通常为batch_size）： 代表一个训练批次（batch）中包含的样本数量。为了高效训练，模型会并行处理多个句子序列。例如，一个形状为 [32, 10] 的张量，表示我们一次性处理32个独立的句子。\n",
    "\n",
    "第二维： 代表单个样本（即一个句子）的长度，也就是该句子中包含的单词或子词（Token）的数量。继续上面的例子（[32, 10]），10 表示这32个句子中的每一个都被统一处理或填充为10个Token长。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9eab69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):                  \n",
    "    def __init__(self, d_model: int, vocab_size: int):                  \n",
    "        \"\"\"d_model:词嵌入的维度， vocab:词表的大小\"\"\"\n",
    "        super(Embedding, self).__init__()                  \n",
    "        self.d_model = d_model                  \n",
    "        self.vocab_size = vocab_size                  \n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)                  \n",
    "\n",
    "    def forward(self, x):                  \n",
    "        # 乘上权重来自于论文 3.4                  \n",
    "        return self.embedding(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d71e78",
   "metadata": {},
   "source": [
    "测试 class Embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b81b32cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:\n",
      " torch.Size([2, 4])\n",
      "input example:\n",
      " tensor([[861, 329,  20, 330],\n",
      "        [921, 808, 470, 583]])\n",
      "output shape:\n",
      " torch.Size([2, 4, 512])\n",
      "output example:\n",
      " tensor([ 19.5487, -55.4443, -32.8522,  -6.5474,   5.4467, -33.1357,  10.2999,\n",
      "         18.8888, -27.1909,  -6.5088,  10.0380,   5.0923,  11.7681,  28.7709,\n",
      "         -8.9583,  22.8899,   9.5049,  -0.2021,  -6.9523, -17.2628, -21.2329,\n",
      "         30.1896, -21.7649,   3.2211, -36.2002,  34.8609,  -1.9186,  12.6291,\n",
      "         -8.8502, -30.2478,  -0.6691,  10.3841,  -3.0758, -34.2872, -48.0336,\n",
      "        -52.2171, -14.6487, -10.1262, -48.9307, -18.0721, -29.8355,   2.2841,\n",
      "         14.4870,   2.2769,  21.6282,   9.0954,  22.8564,  -6.2375, -51.8411,\n",
      "        -13.2375,   3.0120,  15.3333, -30.0134, -29.5732,  27.9618, -19.4803,\n",
      "         21.0745, -48.9125,   2.1010, -60.4926,  -0.8750,   8.5988, -57.8850,\n",
      "         48.1430, -25.5690,  17.5148,  23.1672,  27.8680,  -6.6752,  16.9334,\n",
      "         -5.7527, -25.4094,  34.9158,  48.8239,  34.4755,  -0.3910, -39.2011,\n",
      "         24.8260,  25.1767, -16.7082,   3.1384,   7.1021, -60.8421,  -3.5152,\n",
      "         18.9546,  -1.8635,   6.4356, -25.2367, -13.2954,  22.5885,  -4.2416,\n",
      "        -16.6546,   0.9925, -27.9905,  25.8231, -11.8096, -10.9251, -17.2905,\n",
      "         -5.8973,   0.6511, -14.4351,  -0.4626, -36.2070,   4.7321,  58.3143,\n",
      "         -1.0639,  -8.4507, -40.6155,  18.6225,  -4.5371, -33.1140,  16.2890,\n",
      "         -4.1548,  -1.9794, -26.9025,   0.4358,  17.3995,  -5.3860,  -0.5896,\n",
      "         10.5731,  38.1629,  -4.9830, -21.4544, -27.2977,  13.6485,  -7.1845,\n",
      "         19.4898, -16.6816,   0.6364,   4.0879,   7.1789,  21.7698,  -2.5694,\n",
      "        -19.2778,  38.3152,  26.9230,  -8.5750,  26.5855,   5.6417, -12.6604,\n",
      "        -23.2029,  -1.6840,  -0.6657,   3.1500,   3.3972, -18.1411, -21.5269,\n",
      "         34.9160, -19.0512, -40.2158, -17.4908,  -2.8779,  13.1125,  44.0240,\n",
      "        -16.8712, -28.8992, -35.6591,  -1.5565,   0.7667, -28.7208,  31.9857,\n",
      "          8.2033,   1.9366,   9.2875,  34.6415, -14.4140,  -9.0759,   6.7506,\n",
      "          0.9264,  -8.1726, -46.0577, -21.2948,  61.5766,  -4.9356, -13.3702,\n",
      "         15.5561,  45.9889,  30.7430,  39.1034, -34.6924, -46.6610, -33.4813,\n",
      "        -20.3792, -12.6477, -42.4375, -41.7556,  -5.1194, -25.8502,  -6.3195,\n",
      "          1.2257,  23.9969,  11.8215,  15.2664,  -0.6877,  10.3027,  23.6689,\n",
      "         12.6828,  11.0207, -15.1438, -48.7622,   1.3003,  13.3201,  -4.6494,\n",
      "        -15.6884,  22.3340,   4.7191,  18.8368,  26.2976,  18.0599,  49.8432,\n",
      "         -0.9403,   5.1034,  -7.3444,  -7.3230,  -5.5933, -14.9941,  19.2627,\n",
      "         33.4336,  31.4593, -17.6374,   1.8501,   1.8902,  13.9012,   4.0503,\n",
      "         -0.6254,  36.6847,  -7.9358,  17.9957,  21.8462,  10.8179, -11.6086,\n",
      "          7.2657,  11.9397, -26.2398,  35.2694,  26.8885,  13.1918, -14.6705,\n",
      "         20.1131,   9.3599,  52.8066,  -3.9217,  -9.4948,  26.5497,  -6.9780,\n",
      "        -41.1664,  -8.8367,  26.8479,  10.2286, -16.3835, -55.5924,  -2.1152,\n",
      "         12.1260,   5.5032, -10.8167, -23.3329,   4.2648,  25.7267,  -3.6085,\n",
      "         12.7903,  24.0898, -22.8749,   4.7756,  10.3256,   3.4980,  -7.3694,\n",
      "          2.4422,  28.3239,  -9.1500,  11.1941,  24.7452,   6.1540,  19.3243,\n",
      "         -8.7944,  11.1120, -31.8762, -23.8815,   9.5365,  22.2384,  -4.3823,\n",
      "         30.7662,  14.9942,  -5.6469,  26.9600,  29.0534, -16.9330,  -6.7287,\n",
      "         -7.7124,  39.8175,  -2.6369, -10.6846, -35.0536, -11.1528, -40.7452,\n",
      "         42.3465,  -5.7375,   6.5452,  30.1237,  20.9969,  -6.1030,  27.0036,\n",
      "        -67.3716,  29.4390, -21.1137,   5.4729,  13.6827, -21.7395,   1.8084,\n",
      "         34.7736,   2.4624,  14.7865,  -4.3385,  -7.6646,  19.3266,  -4.6410,\n",
      "         13.8214,  -4.8415,  24.8484,   1.4322,   3.5242,  23.4182, -28.8917,\n",
      "         -3.8247, -13.1154,  16.0883, -19.8680,  59.5279, -13.0987,  -8.7676,\n",
      "        -27.2524,  -8.7013,  13.2170,  73.6200,  29.5389,  15.7457,  45.5892,\n",
      "         13.8473, -12.2039,  -4.0503,  10.7832, -47.3240,  -2.9172,  36.6754,\n",
      "        -27.3221, -21.4256,   8.6841,  44.1950, -20.5608, -22.0316, -21.4869,\n",
      "        -12.7408,  -5.1666,  31.1519,   9.5085,   0.3442,  17.4657,  10.3832,\n",
      "        -26.6457,   8.2291,  11.4380,  -3.7413,  -9.4947,  16.8690, -26.2466,\n",
      "         10.8272,  13.1309,   3.3989,   4.0214, -16.4244,  51.6600, -10.5165,\n",
      "          1.3386,  -0.6719,  26.5999, -35.6297,  20.3174,  -7.6162, -16.1591,\n",
      "         16.9707,  10.6427, -20.1697,  -4.3744,   4.8900, -23.5072,   1.9512,\n",
      "         15.2813,  29.4616,  37.8174,  34.9683, -22.4534, -33.7697,  -8.2291,\n",
      "         -9.5998,  -8.2956, -56.5866, -23.7453,  -0.8398,  17.9972,   8.2939,\n",
      "         19.9877,   7.4731, -17.9708,  -3.0695,  17.1167, -20.4643,   6.4726,\n",
      "         11.1667, -25.7714, -10.5398, -15.5702,  -9.2348,  11.6597,  10.8414,\n",
      "        -26.9194,  -9.1525,  14.4538, -43.8651,  -1.2730,  32.3084,  -9.5062,\n",
      "         21.2449,  -4.2548,  15.8934,  -0.5543,   3.6175,   8.3795, -10.0795,\n",
      "        -14.2907,  18.9063,  18.1247,  -6.7193, -13.5815,   6.4654,  -2.3713,\n",
      "         -8.5281,  10.4589,  14.9058,   7.6152,  15.6307,  29.8699,  12.9360,\n",
      "         22.2156,  17.5412,  18.4082,   4.4404,  -5.1062, -28.3141,  15.6226,\n",
      "         -8.1530, -21.4161, -19.6477, -22.3442,  12.6340, -43.0661, -15.8703,\n",
      "          5.5100,   0.4026,   3.4776, -33.0735,   0.8121,  -9.5814,  -7.3356,\n",
      "         39.2308, -21.7084,  54.7582, -30.8559,  65.4429,  44.9151,   4.7849,\n",
      "        -12.1022,  11.6276,  -2.4431,   0.5014, -18.4923,  -9.7905, -16.0597,\n",
      "          8.9442,  -1.3802,  45.3930,  26.4703,  13.7132,   2.4861, -19.7612,\n",
      "         11.1641,  42.4971, -28.3771,  -0.4222,  -8.6201,  24.2739,  10.0756,\n",
      "        -39.1726, -12.5912,   6.5395,   5.4270,  -4.2466,  -1.7949, -13.1833,\n",
      "         -7.7337,  16.8540, -24.1579,  13.6140,  12.3995, -13.6942,  -1.5439,\n",
      "        -10.6578,  -7.2837, -26.8945,  24.8256,  -0.5423, -36.9329, -45.1131,\n",
      "         -4.0766], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 1. 设置参数\n",
    "d_model = 512  # 词嵌入维度（示例，可自定义）\n",
    "vocab_size = 1000  # 词表大小（需大于输入中的最大索引值）\n",
    "\n",
    "# 2. 创建形状为 [2, 4] 的输入（2个样本，每个样本4个词索引）\n",
    "# 索引值需在 [0, vocab_size-1] 范围内，这里随机生成\n",
    "x = torch.randint(0, vocab_size, (2, 4))  # 形状: torch.Size([2, 4])\n",
    "print(\"input shape:\\n\", x.shape)\n",
    "print(\"input example:\\n\", x)\n",
    "\n",
    "# 3. 实例化嵌入层\n",
    "embedding_layer = Embedding(d_model, vocab_size)\n",
    "\n",
    "# 4. 前向传播\n",
    "output = embedding_layer(x)\n",
    "\n",
    "# 5. 验证输出形状（预期：[2, 4, d_model]）\n",
    "print(\"output shape:\\n\", output.shape)\n",
    "print(\"output example:\\n\", output[0, 0, :])  # 打印前5维"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f3dcb7",
   "metadata": {},
   "source": [
    "## 位置编码器PositionalEncoding\n",
    "\n",
    "由于Transformer无循环或卷积结构，无法直接捕捉序列的位置信息。位置编码器通过正弦和余弦函数生成与词嵌入维度相同的位置向量，将其与词嵌入向量相加，使模型能够区分不同位置的token，确保序列顺序信息在建模过程中不丢失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc5273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):                  \n",
    "    def __init__(self, d_model: int, dropout: float, max_len: int = 5000):                  \n",
    "        \"\"\"d_model:词嵌入维度，dropout:置0比率，max_len:最大长度\"\"\"\n",
    "        super(PositionalEncoding, self).__init__()                  \n",
    "        self.dropout = nn.Dropout(p=dropout)                  \n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)                  \n",
    "        position = torch.arange(0, max_len).unsqueeze(1)                  \n",
    "        # 实现公式 3.5, 10000^(-2i/d_model) = exp(2i × (-ln(10000)/d_model))                  \n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))                  \n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)                  \n",
    "        pe[:, 1::2] = torch.cos(position * div_term)                  \n",
    "\n",
    "        pe = pe.unsqueeze(0)# (1, max_len, d_model)                  \n",
    "        self.register_buffer('pe', pe)                  \n",
    "\n",
    "    def forward(self, x):                  \n",
    "        # (batch, max_len, d_model)                  \n",
    "        # 论文不参与反向传播        \n",
    "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False)                  \n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d774b10",
   "metadata": {},
   "source": [
    "架构图中位置编码器与embedding中间有个\"+\"号，对应到正向传播代码就是：\n",
    "\n",
    "x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cbce25",
   "metadata": {},
   "source": [
    "## dropout\n",
    "\n",
    "在神经网络中，dropout 是防止过拟合的重要手段。当模型计算出矩阵后，会随机将一部分权重值置为 0（丢弃比例通常设为 0.1），再进行后续的操作。这种随机丢弃机制打破了神经元间的过度依赖，避免模型对训练数据中特定位置的关联过度拟合，迫使模型学习更通用的特征关联模式，从而提升在未见数据上的泛化能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759cc19e",
   "metadata": {},
   "source": [
    "# Encoder部分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efedfda",
   "metadata": {},
   "source": [
    "## MultiHeadAttention 多头注意力\n",
    "\n",
    "多头注意力是Transformer的核心组件，它将输入向量通过多个并行的注意力头分别计算注意力分布，再将结果拼接融合。这种设计能让模型同时捕捉不同尺度、不同维度的语义关联（如局部依赖和全局依赖），PyTorch中可通过自定义线性层和注意力计算逻辑实现多头并行处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8609fdbf",
   "metadata": {},
   "source": [
    "![MultiHeadAttention](figures/b5908f57cb73b58f93e6a5a139849b49.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763e62cd",
   "metadata": {},
   "source": [
    "注意力机制\n",
    "\n",
    "注意力机制的核心思想源于人类视觉和认知系统：在处理信息时，我们不会同等地对待所有输入，而是会选择性地聚焦于与当前任务最相关的部分，同时忽略其他不重要的信息。\n",
    "\n",
    "在神经网络中，这一思想被抽象为一个可计算的数学过程。它的关键作用可以概括为 “权重分配” 。具体来说，对于一个查询（Query），模型会计算它与一系列键（Key）的相似度，然后根据这些相似度得分（即注意力权重）来对对应的值（Value）进行加权求和。这个权重就代表了模型在处理当前查询时，应该对每个值投入多少“注意力”。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7a1d0d",
   "metadata": {},
   "source": [
    "这段代码出现了概念：掩码张量（attn.masked_fill）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4942f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(self, query, key, value, mask=None, dropout=None):                  \n",
    "    d_k = query.shape[-1] # d_model:词嵌入维度\n",
    "\n",
    "    # torch.matmul A的最后一个维度 必须等于B的倒数第二个维度                  \n",
    "    attn = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)                  \n",
    "    if mask is not None:                  \n",
    "        attn = attn.masked_fill(mask == 0, -1e9)                  \n",
    "    # 最后一维进行softmax操作                  \n",
    "    attn = F.softmax(attn, dim=-1)                  \n",
    "    if dropout is not None:                  \n",
    "        attn = dropout(attn)                  \n",
    "    return torch.matmul(attn, value), attn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7deb1c5",
   "metadata": {},
   "source": [
    "Multi-head可以在更细致的层⾯上提取不同head的特征，总体计算量和单⼀head相同的情况下，提取特征的效果更佳。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c199479",
   "metadata": {},
   "source": [
    "![MultiHeadAttention](figures/multiheadattention.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c878c",
   "metadata": {},
   "source": [
    "最关键部分是理解清楚矩阵的结构变换：\n",
    "\n",
    "多头处理前：初始状态是一个三维矩阵(batch_size, max_len, d_model)，多头分割后变成了4维矩阵(batch_size, max_len, head, d_k)，为了方便多头处理将head所在维度前移(batch_size, head, max_len, d_k)\n",
    "\n",
    "多头处理后，又重新变回三维矩阵，与输入结构保持一致(batch_size, max_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0975cf6e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b5775a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):                  \n",
    "    def __init__(self, head: int, d_model: int, dropout: float = 0.1):                  \n",
    "        \"\"\"head代表头数，d_model代表词嵌⼊的维度\"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()                  \n",
    "\n",
    "        assert d_model % head == 0, \"d_model 必须可以整除 head\"                  \n",
    "        self.d_k = d_model // head# 每个头获得的分割词向量维度d_k                  \n",
    "        self.head = head                  \n",
    "\n",
    "        self.w_q = nn.Linear(d_model, d_model, bias=False)                  \n",
    "        self.w_k = nn.Linear(d_model, d_model, bias=False)                  \n",
    "        self.w_v = nn.Linear(d_model, d_model, bias=False)                  \n",
    "        self.w_o = nn.Linear(d_model, d_model, bias=False)                  \n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)                  \n",
    "\n",
    "    # 注意力                  \n",
    "    def attention(self, query, key, value, mask=None, dropout=None):                  \n",
    "        d_k = query.shape[-1]                  \n",
    "\n",
    "        # torch.matmul A的最后一个维度 必须等于 B的倒数第二个维度                  \n",
    "        attn = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)                  \n",
    "        if mask is not None:                  \n",
    "            attn = attn.masked_fill(mask == 0, -1e9)                  \n",
    "        # 最后一维进行softmax操作                  \n",
    "        attn = F.softmax(attn, dim=-1)                  \n",
    "        if dropout is not None:                  \n",
    "            attn = dropout(attn)                  \n",
    "        return torch.matmul(attn, value), attn                  \n",
    "\n",
    "    def forward(self, q, k, v, mask=None):                  \n",
    "        if mask is not None:                  \n",
    "            mask = mask.unsqueeze(0)                  \n",
    "\n",
    "        query = self.w_q(q)# Q                  \n",
    "        key = self.w_k(k)# K                  \n",
    "        value = self.w_v(v)# V                  \n",
    "\n",
    "        batch_size = query.size(0)                  \n",
    "        # 多头切割                  \n",
    "        # (batch_size, max_len, d_model) -->(batch_size, max_len, head, d_k) -->(batch_size, head, max_len, d_k)                  \n",
    "        query = query.view(batch_size, -1, self.head, self.d_k).transpose(1, 2)                  \n",
    "        key = key.view(batch_size, -1, self.head, self.d_k).transpose(1, 2)                  \n",
    "        value = value.view(batch_size, -1, self.head, self.d_k).transpose(1, 2)                  \n",
    "\n",
    "        x, self.attn = self.attention(query, key, value, mask=mask, dropout=self.dropout)                  \n",
    "        # (batch_size, head, max_len, d_k) -> (batch_size, max_len, head * d_k) -> (batch_size, max_len, d_model)                  \n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.head * self.d_k)                  \n",
    "        return self.w_o(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f049b1b",
   "metadata": {},
   "source": [
    "## FeedForward 前馈全连接层\n",
    "\n",
    "前馈全连接层对多头注意力输出的每个位置向量进行独立的非线性变换，通常采用“线性层+激活函数+线性层”的结构（如ReLU或GELU激活）。它能将注意力机制捕捉到的关联特征进一步映射到更复杂的表示空间，增强模型的非线性拟合能力。\n",
    "\n",
    "开发实现中，一般采用带有dropout的实用公式：\n",
    "\n",
    "FFN(x) = dropout(σ(xW₁ + b₁))W₂ + b₂\n",
    "\n",
    "其中 σ 是激活函数，在原始论文中是 ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eed2d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):                  \n",
    "    def __init__(self, d_model: int, d_ff: int, dropout=0.1):                  \n",
    "        \"\"\"d_ff：第二个线性层的输入维度\"\"\"\n",
    "        super(FeedForward, self).__init__()                  \n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)  # 包含 W₁ 和 b₁\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)  # 包含 W₂ 和 b₂\n",
    "        self.dropout = nn.Dropout(dropout)                  \n",
    "\n",
    "    def forward(self, x):                  \n",
    "        # 论文中 3.3 FFN(x)                  \n",
    "        # self.linear1(x) 实际计算: x @ W₁.T + b₁\n",
    "        # self.linear2(...) 实际计算: ... @ W₂.T + b₂        \n",
    "        return self.linear_2(self.dropout(F.relu(self.linear_1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce87fe",
   "metadata": {},
   "source": [
    "## LayerNorm 规范化层\n",
    "\n",
    "规范化层用于稳定模型训练过程，通过对输入张量按样本维度进行均值和方差归一化，抑制梯度消失或爆炸问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77679ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):                  \n",
    "    # 对每个样本不同位置的向量求均值和方差，然后进行归一化                  \n",
    "    def __init__(self, features: int, eps: float = 1e-6):                  \n",
    "        \"\"\" features, 表示词嵌⼊的维度，样本的特征数量\n",
    "        eps是⼀个⾜够⼩的数, 在规范化公式的分⺟中出现,防⽌分⺟为0.默认是1e-6.\"\"\"\n",
    "        super(LayerNorm, self).__init__()                  \n",
    "        self.eps = eps                  \n",
    "        self.alpha = nn.Parameter(torch.ones(features))                  \n",
    "        self.bias = nn.Parameter(torch.zeros(features))                  \n",
    "\n",
    "    def forward(self, x):                  \n",
    "        # 最后一个维度的均值                  \n",
    "        mean = x.mean(dim=-1, keepdim=True)                  \n",
    "        # 最后一个维度的标准差                  \n",
    "        std = x.std(dim=-1, keepdim=True)                  \n",
    "        return self.alpha * (x - mean) / (std + self.eps) + self.bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c93c04",
   "metadata": {},
   "source": [
    "## SublayerConnection 子层连接结构\n",
    "\n",
    "子层连接结构将每个编码器子层（如多头注意力、前馈层）的输出与输入进行残差连接，再经过层归一化处理。这种“残差+归一化”的设计能有效缓解深层模型的训练困难，让梯度更顺畅地反向传播，是Transformer能堆叠多层的关键保障。\n",
    "\n",
    "Add & Norm模块接在每⼀个Encoder Block和Decoder Block中的每⼀个⼦层的后⾯。具体来说Add表示残差连接, Norm表示LayerNorm。\n",
    "\n",
    "Add残差连接的作⽤：和其他神经⽹络模型中的残差连接作⽤⼀致，都是为了将信息传递的更深，增强模型的拟合能⼒。试验表明残差连接的确增强了模型的表现。\n",
    "\n",
    "Norm的作⽤：随着⽹络层数的额增加，通过多层的计算后参数可能会出现过⼤、过⼩、⽅差变⼤等现象，这会导致学习过程出现异常，模型的收敛⾮常慢。因此对每⼀层计算后的数值进⾏规范化可以提升模型的表现。\n",
    "\n",
    "论文中数学表达形式为: LayerNorm(x + Sublayer(x)), 其中Sublayer(x)为⼦层的输出\n",
    "\n",
    "这里实现和论文中略有不同，先进行 norm 再进行 self-attention 或 feed-forward。也就是说，sublayer可以传多头注意力MultiHeadAttention，也只可以传前馈全连接层FeedForward。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1ecb9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):                  \n",
    "    def __init__(self, features: int, dropout: float = 0.1):                  \n",
    "        super(SublayerConnection, self).__init__()                  \n",
    "        self.norm = LayerNorm(features)                  \n",
    "        self.dropout = nn.Dropout(dropout)                  \n",
    "\n",
    "    def forward(self, x, sublayer):                  \n",
    "        # 此处和论文中 transformer 给的图略有不同, 先进行 norm 再进行 self-attention 或 feed-forward                  \n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1475c4c9",
   "metadata": {},
   "source": [
    "## EncoderLayer 编码器层\n",
    "\n",
    "编码器层是编码器的基本构建单元，由“多头注意力子层+子层连接”和“前馈全连接子层+子层连接”组成。每个EncoderLayer完成一次完整的特征提取与变换，通过重复堆叠多层EncoderLayer，模型能逐步捕捉序列中复杂的语义和结构信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea98b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):                  \n",
    "    def __init__(self, features: int, self_attn: MultiHeadAttention,                  \n",
    "                 feed_forward: FeedForward, dropout: float = 0.1):                  \n",
    "        super(EncoderLayer, self).__init__()                  \n",
    "\n",
    "        self.features = features                  \n",
    "        self.self_attn = self_attn                  \n",
    "        self.feed_forward = feed_forward                  \n",
    "\n",
    "        # 编码器层中有两个⼦层连接结构                  \n",
    "        self.sublayer = nn.ModuleList(                  \n",
    "            [SublayerConnection(features, dropout) for _ in range(2)]                  \n",
    "        )                  \n",
    "\n",
    "    def forward(self, x, mask):                  \n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))                  \n",
    "        return self.sublayer[1](x, self.feed_forward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f107058",
   "metadata": {},
   "source": [
    "## Encoder 编码器\n",
    "\n",
    "编码器由N层EncoderLayer堆叠而成。它接收经过词嵌入和位置编码处理后的源序列输入，经过多层特征提取后输出源序列的上下文表示向量，该向量包含了源序列的全局语义信息，将作为解码器的注意力输入，为目标序列生成提供依据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddce3db2",
   "metadata": {},
   "source": [
    "![transformer_encoder](figures/transformer_encoder.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44fd73f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cloneModules(module, N):                  \n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86623c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):                  \n",
    "    def __init__(self, layer: EncoderLayer, N: int):                  \n",
    "        \"\"\"初始化函数的两个参数分别代表编码器层和编码器层的个数\"\"\"\n",
    "        super(Encoder, self).__init__()                  \n",
    "        self.layers = cloneModules(layer, N)                  \n",
    "        self.norm = LayerNorm(layer.features)                  \n",
    "\n",
    "    def forward(self, x, mask):                  \n",
    "        for layer in self.layers:                  \n",
    "            x = layer(x, mask)                  \n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac09902e",
   "metadata": {},
   "source": [
    "# Decoder 解码器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bab882c",
   "metadata": {},
   "source": [
    "## DecoderLayer\n",
    "\n",
    "解码器的核心组件，包含三个子层：掩码自注意力层、编码器-解码器注意力层和前馈网络层，每层后都应用残差连接和规范化。\n",
    "\n",
    "架构图中下边的多头注意力来自输入端，Q=K=V；上面的多头注意力，Q来自下面的多头注意力，K、V来自左边编码器的输出，即Q!=K=V。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac7106c",
   "metadata": {},
   "source": [
    "![transformerDecoder](figures/transformer_decoder.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "559e4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):                  \n",
    "    def __init__(self, features: int, self_attn: MultiHeadAttention, cross_attn: MultiHeadAttention,                  \n",
    "                 feed_forward: FeedForward, dropout: float):                  \n",
    "        super(DecoderLayer, self).__init__()                  \n",
    "        self.features = features                  \n",
    "        self.self_attn = self_attn                  \n",
    "        self.cross_attn = cross_attn                  \n",
    "        self.feed_forward = feed_forward                  \n",
    "        self.sublayer = cloneModules(SublayerConnection(features, dropout), 3)                  \n",
    "\n",
    "    def forward(self, x, encoder_output, source_mask, target_mask):                  \n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, target_mask))                  \n",
    "        x = self.sublayer[1](x, lambda x: self.cross_attn(x, encoder_output, encoder_output, source_mask))                  \n",
    "        return self.sublayer[2](x, self.feed_forward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3649958",
   "metadata": {},
   "source": [
    "## Decoder 解码器\n",
    "\n",
    "由多个解码器层堆叠组成，逐步融合编码器输出和已生成序列信息，生成目标语言的序列表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99e4413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):                  \n",
    "    def __init__(self, layer: DecoderLayer, N: int):                  \n",
    "        super(Decoder, self).__init__()                  \n",
    "        self.layers = cloneModules(layer, N)                  \n",
    "        self.norm = LayerNorm(layer.features)                  \n",
    "\n",
    "    def forward(self, x, encoder_output, source_mask, target_mask):                  \n",
    "        for layer in self.layers:                  \n",
    "            x = layer(x, encoder_output, source_mask, target_mask)                  \n",
    "        return self.norm(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e164d0a8",
   "metadata": {},
   "source": [
    "# Generator 生成器类（线性层+softmax计算层）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81870012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):                  \n",
    "    def __init__(self, d_model, vocab_size):                  \n",
    "        super(Generator, self).__init__()                  \n",
    "        self.project = nn.Linear(d_model, vocab_size)                  \n",
    "\n",
    "    def forward(self, x):                  \n",
    "        return F.log_softmax(self.project(x), dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9f87b3",
   "metadata": {},
   "source": [
    "# Transformer 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df11d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):                  \n",
    "    def __init__(self, encoder: Encoder, decoder: Decoder,                  \n",
    "                 source_embed: Embedding, target_embed: Embedding,                  \n",
    "                 source_pos: PositionalEncoding, target_pos: PositionalEncoding,                  \n",
    "                 generator: Generator):                  \n",
    "        super(Transformer, self).__init__()                  \n",
    "        self.encoder = encoder                  \n",
    "        self.decoder = decoder                  \n",
    "        self.source_embed = source_embed                  \n",
    "        self.target_embed = target_embed                  \n",
    "        self.source_pos = source_pos                  \n",
    "        self.target_pos = target_pos                  \n",
    "        self.generator = generator                  \n",
    "\n",
    "    def encode(self, source, source_mask):                  \n",
    "        return self.encoder(self.source_pos(self.source_embed(source)), source_mask)                  \n",
    "\n",
    "    def decode(self, encoder_output, source_mask, target, target_mask):                  \n",
    "        return self.decoder(self.target_pos(self.target_embed(target)), encoder_output, source_mask, target_mask)                  \n",
    "\n",
    "    def forward(self, source, target, source_mask, target_mask):                  \n",
    "        return self.decode(self.encode(source, source_mask), source_mask, target, target_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e36cfd",
   "metadata": {},
   "source": [
    "# 构建模型\n",
    "参照python编码行业规范，编写构建transformer函数方便初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "378e6877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transformer(source_vocab: int, target_vocab: int,                  \n",
    "                      N: int = 6, d_model: int = 512, d_ff: int = 2048, head: int = 8, dropout: float = 0.1):                  \n",
    "    source_embed = Embedding(d_model, source_vocab)                  \n",
    "    target_embed = Embedding(d_model, target_vocab)                  \n",
    "\n",
    "    source_pos = PositionalEncoding(d_model, dropout)                  \n",
    "    target_pos = PositionalEncoding(d_model, dropout)                  \n",
    "\n",
    "    c = copy.deepcopy                  \n",
    "    attn = MultiHeadAttention(head, d_model)                  \n",
    "    ff = FeedForward(d_model, d_ff, dropout)                  \n",
    "\n",
    "    # nn.Sequential是一个顺序容器，用于将多个网络层按顺序组合在一起                  \n",
    "    model = Transformer(                  \n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),                  \n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),                  \n",
    "        source_embed, target_embed,                  \n",
    "        source_pos, target_pos,                  \n",
    "        Generator(d_model, target_vocab))                  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e6f5eb",
   "metadata": {},
   "source": [
    "# 打印模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a595c828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder): Encoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-7): 8 x EncoderLayer(\n",
      "        (self_attn): MultiHeadAttention(\n",
      "          (w_q): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (w_k): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (w_v): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (w_o): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0-1): 2 x SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm()\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-7): 8 x DecoderLayer(\n",
      "        (self_attn): MultiHeadAttention(\n",
      "          (w_q): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (w_k): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (w_v): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (w_o): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (cross_attn): MultiHeadAttention(\n",
      "          (w_q): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (w_k): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (w_v): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (w_o): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0-2): 3 x SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm()\n",
      "  )\n",
      "  (source_embed): Embedding(\n",
      "    (embedding): Embedding(1000, 512)\n",
      "  )\n",
      "  (target_embed): Embedding(\n",
      "    (embedding): Embedding(1000, 512)\n",
      "  )\n",
      "  (source_pos): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (target_pos): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (generator): Generator(\n",
      "    (project): Linear(in_features=512, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':                  \n",
    "    source_vocab = 1000                  \n",
    "    target_vocab = 1000                  \n",
    "    N = 8                  \n",
    "    transformer = make_transformer(source_vocab, target_vocab, N)                  \n",
    "    print(transformer)                  \n",
    "\n",
    "    # 0维：batch_size，不同的句子                  \n",
    "    # 1维：句子中的token                  \n",
    "    torch.random.manual_seed(42)                  \n",
    "    x = torch.randint(0,1000,(2,4))                  \n",
    "\n",
    "    mask = torch.zeros(8, 4, 4)                  \n",
    "    test_result = transformer(x, x, mask, mask)                  \n",
    "    print(test_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f041a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fennomixdocs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
